{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment                                            content\n",
       "0  1956967341       empty  @tiffanylue i know  i was listenin to bad habi...\n",
       "1  1956967666     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2  1956967696     sadness                Funeral ceremony...gloomy friday...\n",
       "3  1956967789  enthusiasm               wants to hang out with friends SOON!\n",
       "4  1956968416     neutral  @dannycastillo We want to trade with someone w..."
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/campusx-official/jupyter-masterclass/main/tweet_emotions.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@JohnLloydTaylor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>love</td>\n",
       "      <td>Happy Mothers Day  All my love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>love</td>\n",
       "      <td>Happy Mother's Day to all the mommies out ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>happiness</td>\n",
       "      <td>@niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>love</td>\n",
       "      <td>@mopedronin bullet train from tokyo    the gf ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentiment                                            content\n",
       "0           empty  @tiffanylue i know  i was listenin to bad habi...\n",
       "1         sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2         sadness                Funeral ceremony...gloomy friday...\n",
       "3      enthusiasm               wants to hang out with friends SOON!\n",
       "4         neutral  @dannycastillo We want to trade with someone w...\n",
       "...           ...                                                ...\n",
       "39995     neutral                                   @JohnLloydTaylor\n",
       "39996        love                     Happy Mothers Day  All my love\n",
       "39997        love  Happy Mother's Day to all the mommies out ther...\n",
       "39998   happiness  @niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...\n",
       "39999        love  @mopedronin bullet train from tokyo    the gf ...\n",
       "\n",
       "[40000 rows x 2 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns= ['tweet_id'] , inplace= True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### workin on binary classification for ease thus  , \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['empty', 'sadness', 'enthusiasm', 'neutral', 'worry', 'surprise',\n",
       "       'love', 'fun', 'hate', 'happiness', 'boredom', 'relief', 'anger'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sadness</td>\n",
       "      <td>I should be sleep, but im not! thinking about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sadness</td>\n",
       "      <td>@charviray Charlene my love. I miss you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sadness</td>\n",
       "      <td>@kelcouch I'm sorry  at least it's Friday?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39986</th>\n",
       "      <td>happiness</td>\n",
       "      <td>going to watch boy in the striped pj's hope i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39987</th>\n",
       "      <td>happiness</td>\n",
       "      <td>gave the bikes a thorough wash, degrease it an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39988</th>\n",
       "      <td>happiness</td>\n",
       "      <td>had SUCH and AMAZING time last night, McFly we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39994</th>\n",
       "      <td>happiness</td>\n",
       "      <td>Succesfully following Tayla!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>happiness</td>\n",
       "      <td>@niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10374 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                            content\n",
       "1        sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2        sadness                Funeral ceremony...gloomy friday...\n",
       "6        sadness  I should be sleep, but im not! thinking about ...\n",
       "8        sadness            @charviray Charlene my love. I miss you\n",
       "9        sadness         @kelcouch I'm sorry  at least it's Friday?\n",
       "...          ...                                                ...\n",
       "39986  happiness  going to watch boy in the striped pj's hope i ...\n",
       "39987  happiness  gave the bikes a thorough wash, degrease it an...\n",
       "39988  happiness  had SUCH and AMAZING time last night, McFly we...\n",
       "39994  happiness                      Succesfully following Tayla!!\n",
       "39998  happiness  @niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...\n",
       "\n",
       "[10374 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['sentiment'].isin(['happiness' , 'sadness'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = df[df['sentiment'].isin(['happiness' , 'sadness'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ujjwal\\AppData\\Local\\Temp\\ipykernel_400\\532746371.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  final_df.replace({'happiness' : 1 , 'sadness'  : 0 }, inplace = True)\n",
      "C:\\Users\\Ujjwal\\AppData\\Local\\Temp\\ipykernel_400\\532746371.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df.replace({'happiness' : 1 , 'sadness'  : 0 }, inplace = True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>I should be sleep, but im not! thinking about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>@charviray Charlene my love. I miss you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>@kelcouch I'm sorry  at least it's Friday?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            content\n",
       "1          0  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2          0                Funeral ceremony...gloomy friday...\n",
       "6          0  I should be sleep, but im not! thinking about ...\n",
       "8          0            @charviray Charlene my love. I miss you\n",
       "9          0         @kelcouch I'm sorry  at least it's Friday?"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.replace({'happiness' : 1 , 'sadness'  : 0 }, inplace = True)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test spli\n",
    "from sklearn.model_selection import train_test_split \n",
    "train_data ,  test_data  = train_test_split(final_df , test_size= 0.2 , random_state= 42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating raw , train , test file \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/data_ingestion.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/data_ingestion.py\n",
    "#data loading\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/campusx-official/jupyter-masterclass/main/tweet_emotions.csv')\n",
    "df.drop(columns= ['tweet_id'] , inplace= True)\n",
    "\n",
    "final_df = df[df['sentiment'].isin(['happiness' , 'sadness'])]\n",
    "final_df.replace({'happiness' : 1 , 'sadness'  : 0 }, inplace = True)\n",
    "\n",
    "#train test spli\n",
    "train_data ,  test_data  = train_test_split(final_df , test_size= 0.2 , random_state= 42)\n",
    "data_path = os.path.join('data' , 'raw' )\n",
    "os.makedirs(data_path, exist_ok= True)\n",
    "\n",
    "train_data.to_csv(os.path.join(data_path , 'train.csv'))\n",
    "test_data.to_csv(os.path.join(data_path , 'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ml-pipeline-demo\\src\\data_ingestion.py:12: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  final_df.replace({'happiness' : 1 , 'sadness'  : 0 }, inplace = True)\n",
      "D:\\ml-pipeline-demo\\src\\data_ingestion.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df.replace({'happiness' : 1 , 'sadness'  : 0 }, inplace = True)\n"
     ]
    }
   ],
   "source": [
    "%run -i src/data_ingestion.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(data_path, exist_ok= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data ingenstion done 🙏🙏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now add to dvc state , inorder to add into dvc we need to declear few thigns\n",
    "\n",
    "-n name of state (generally , this name will be python file name)\n",
    "-d (inorder to execute currect state , which file is need to run for example\n",
    "src/dataingestion will run  , raw test and train thus )\n",
    "\n",
    "-p parameters  (configuration related parameters ) [skipped for now ]\n",
    "\n",
    "-o (what is the  output of the currect stage )\n",
    "for example what will be be output of data _ingestion.py\n",
    "  answer data folders \n",
    "i.e data/raw\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now write a code  in command line\n",
    "dev statge add -n data-ingestion -d src/data_ingestion.py -o data/raw  [and at last \n",
    "    add coomand to run the file\n",
    "    python src/data_ingestion.py\n",
    "\n",
    "]\n",
    "\n",
    "this coude will generate a new file called dvc.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  #inorder to run the pipeline \n",
    "type dvc repro :\n",
    "dvc run will automaticaly search for dvc yamal file and run the file \n",
    "repro stands for reproduce\n",
    "\n",
    "delete the data folder and run  , you will see new data folder has been created "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA transformation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(os.path.join('data' , 'raw' , 'train.csv'))\n",
    "test_data = pd.read_csv(os.path.join('data' ,'raw' , 'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23531</td>\n",
       "      <td>0</td>\n",
       "      <td>&amp;quot;My problem isn't that I miss you... 'cau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8051</td>\n",
       "      <td>0</td>\n",
       "      <td>That's it? It's done already? This is one proo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11499</td>\n",
       "      <td>0</td>\n",
       "      <td>I am so hungry! And there is no food for me to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31288</td>\n",
       "      <td>1</td>\n",
       "      <td>Feet hurt...finally in bed...will not forget t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18561</td>\n",
       "      <td>0</td>\n",
       "      <td>really ill atm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8294</th>\n",
       "      <td>21697</td>\n",
       "      <td>1</td>\n",
       "      <td>@chocolatesuze yes yes you should! Especially ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8295</th>\n",
       "      <td>19445</td>\n",
       "      <td>0</td>\n",
       "      <td>@kickzfadayz Our boy better get it in tonight!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8296</th>\n",
       "      <td>20216</td>\n",
       "      <td>1</td>\n",
       "      <td>tafe was actually quite good. for once</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8297</th>\n",
       "      <td>3258</td>\n",
       "      <td>0</td>\n",
       "      <td>10 minutes to boarding; 14 hours to home. no w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8298</th>\n",
       "      <td>27810</td>\n",
       "      <td>0</td>\n",
       "      <td>Intel gfx driver situation much better with re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8299 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  sentiment                                            content\n",
       "0          23531          0  &quot;My problem isn't that I miss you... 'cau...\n",
       "1           8051          0  That's it? It's done already? This is one proo...\n",
       "2          11499          0  I am so hungry! And there is no food for me to...\n",
       "3          31288          1  Feet hurt...finally in bed...will not forget t...\n",
       "4          18561          0                                     really ill atm\n",
       "...          ...        ...                                                ...\n",
       "8294       21697          1  @chocolatesuze yes yes you should! Especially ...\n",
       "8295       19445          0  @kickzfadayz Our boy better get it in tonight!...\n",
       "8296       20216          1             tafe was actually quite good. for once\n",
       "8297        3258          0  10 minutes to boarding; 14 hours to home. no w...\n",
       "8298       27810          0  Intel gfx driver situation much better with re...\n",
       "\n",
       "[8299 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Ujjwal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ujjwal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lemmatization(text):\n",
    "    lemmatizer= WordNetLemmatizer()\n",
    "\n",
    "    text = text.split()\n",
    "\n",
    "    text=[lemmatizer.lemmatize(y) for y in text]\n",
    "\n",
    "    return \" \" .join(text)\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    Text=[i for i in str(text).split() if i not in stop_words]\n",
    "    return \" \".join(Text)\n",
    "\n",
    "def removing_numbers(text):\n",
    "    text=''.join([i for i in text if not i.isdigit()])\n",
    "    return text\n",
    "\n",
    "def lower_case(text):\n",
    "\n",
    "    text = text.split()\n",
    "\n",
    "    text=[y.lower() for y in text]\n",
    "\n",
    "    return \" \" .join(text)\n",
    "\n",
    "def removing_punctuations(text):\n",
    "    ## Remove punctuations\n",
    "    text = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,،-./:;<=>؟?@[\\]^_`{|}~\"\"\"), ' ', text)\n",
    "    text = text.replace('؛',\"\", )\n",
    "\n",
    "    ## remove extra whitespace\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text =  \" \".join(text.split())\n",
    "    return text.strip()\n",
    "\n",
    "def removing_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "def remove_small_sentences(df):\n",
    "    for i in range(len(df)):\n",
    "        if len(df.text.iloc[i].split()) < 3:\n",
    "            df.text.iloc[i] = np.nan\n",
    "\n",
    "def normalize_text(df):\n",
    "    df.content=df.content.apply(lambda content : lower_case(content))\n",
    "    df.content=df.content.apply(lambda content : remove_stop_words(content))\n",
    "    df.content=df.content.apply(lambda content : removing_numbers(content))\n",
    "    df.content=df.content.apply(lambda content : removing_punctuations(content))\n",
    "    df.content=df.content.apply(lambda content : removing_urls(content))\n",
    "    df.content=df.content.apply(lambda content : lemmatization(content))\n",
    "    return df\n",
    "\n",
    "def normalized_sentence(sentence):\n",
    "    sentence= lower_case(sentence)\n",
    "    sentence= remove_stop_words(sentence)\n",
    "    sentence= removing_numbers(sentence)\n",
    "    sentence= removing_punctuations(sentence)\n",
    "    sentence= removing_urls(sentence)\n",
    "    sentence= lemmatization(sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hellow nam ujjwal basnet'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_sentence(f\"Hellow my nam is 1232 ujjwal basnet {534534}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed_data = normalize_text(train_data)\n",
    "test_processed_data = normalize_text(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join('data' , 'processed')\n",
    "os.makedirs(path, exist_ok= True)\n",
    "train_processed_data.to_csv(os.path.join(path ,'train_processed.csv' ))\n",
    "test_processed_data.to_csv(os.path.join(path ,'test_processed.csv' ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## writing data_preprocessing  file now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/data_preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/data_preprocessing.py \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "train_data = pd.read_csv(os.path.join('data' , 'raw' , 'train.csv'))\n",
    "test_data = pd.read_csv(os.path.join('data' ,'raw' , 'test.csv'))\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "def lemmatization(text):\n",
    "    lemmatizer= WordNetLemmatizer()\n",
    "\n",
    "    text = text.split()\n",
    "\n",
    "    text=[lemmatizer.lemmatize(y) for y in text]\n",
    "\n",
    "    return \" \" .join(text)\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    Text=[i for i in str(text).split() if i not in stop_words]\n",
    "    return \" \".join(Text)\n",
    "\n",
    "def removing_numbers(text):\n",
    "    text=''.join([i for i in text if not i.isdigit()])\n",
    "    return text\n",
    "\n",
    "def lower_case(text):\n",
    "\n",
    "    text = text.split()\n",
    "\n",
    "    text=[y.lower() for y in text]\n",
    "\n",
    "    return \" \" .join(text)\n",
    "\n",
    "def removing_punctuations(text):\n",
    "    ## Remove punctuations\n",
    "    text = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,،-./:;<=>؟?@[\\]^_`{|}~\"\"\"), ' ', text)\n",
    "    text = text.replace('؛',\"\", )\n",
    "\n",
    "    ## remove extra whitespace\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text =  \" \".join(text.split())\n",
    "    return text.strip()\n",
    "\n",
    "def removing_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "def remove_small_sentences(df):\n",
    "    for i in range(len(df)):\n",
    "        if len(df.text.iloc[i].split()) < 3:\n",
    "            df.text.iloc[i] = np.nan\n",
    "\n",
    "def normalize_text(df):\n",
    "    df.content=df.content.apply(lambda content : lower_case(content))\n",
    "    df.content=df.content.apply(lambda content : remove_stop_words(content))\n",
    "    df.content=df.content.apply(lambda content : removing_numbers(content))\n",
    "    df.content=df.content.apply(lambda content : removing_punctuations(content))\n",
    "    df.content=df.content.apply(lambda content : removing_urls(content))\n",
    "    df.content=df.content.apply(lambda content : lemmatization(content))\n",
    "    return df\n",
    "\n",
    "def normalized_sentence(sentence):\n",
    "    sentence= lower_case(sentence)\n",
    "    sentence= remove_stop_words(sentence)\n",
    "    sentence= removing_numbers(sentence)\n",
    "    sentence= removing_punctuations(sentence)\n",
    "    sentence= removing_urls(sentence)\n",
    "    sentence= lemmatization(sentence)\n",
    "    return sentence\n",
    "\n",
    "\n",
    "train_processed_data = normalize_text(train_data)\n",
    "test_processed_data = normalize_text(test_data)\n",
    "\n",
    "path = os.path.join('data' , 'processed')\n",
    "os.makedirs(path, exist_ok= True)\n",
    "train_processed_data.to_csv(os.path.join(path ,'train_processed.csv' ))\n",
    "test_processed_data.to_csv(os.path.join(path ,'test_processed.csv' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Ujjwal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ujjwal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "%run src/data_preprocessing.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### row run \n",
    "###  dvc stage add -n data_preprocessing -d src/data_preprocessing.py -o data/processed python src/data_preproecssing.py \n",
    "### to add on dvc\n",
    "\n",
    "### also you can use dvc dag to  visulalize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but this is wrong  ,we should also give  , previous output as another dependency\n",
    "i.e -d data/raw\n",
    "so our command should be \n",
    "dvc stage add -n data_preprocessing -d src/data_preprocessing.py -d data/raw-o data/processed python src/data_preproecssing.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " dvc add stage add -n data_preprocessing -d src/data_preprocessing -d data/raw -0 data/processed python src/data_preprocessing.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Feature Engeneering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#featch the data from data/preocessed\n",
    "train_data = pd.read_csv(os.path.join('data' , 'processed' , 'train_processed.csv'))\n",
    "test_data = pd.read_csv(os.path.join('data' ,'processed' , 'test_processed.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove missing values\n",
    "train_data.fillna('', inplace = True)\n",
    "test_data.fillna('',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23531</th>\n",
       "      <td>0</td>\n",
       "      <td>&amp;quot;My problem isn't that I miss you... 'cau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8051</th>\n",
       "      <td>0</td>\n",
       "      <td>That's it? It's done already? This is one proo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11499</th>\n",
       "      <td>0</td>\n",
       "      <td>I am so hungry! And there is no food for me to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31288</th>\n",
       "      <td>1</td>\n",
       "      <td>Feet hurt...finally in bed...will not forget t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18561</th>\n",
       "      <td>0</td>\n",
       "      <td>really ill atm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21697</th>\n",
       "      <td>1</td>\n",
       "      <td>@chocolatesuze yes yes you should! Especially ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19445</th>\n",
       "      <td>0</td>\n",
       "      <td>@kickzfadayz Our boy better get it in tonight!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20216</th>\n",
       "      <td>1</td>\n",
       "      <td>tafe was actually quite good. for once</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>0</td>\n",
       "      <td>10 minutes to boarding; 14 hours to home. no w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27810</th>\n",
       "      <td>0</td>\n",
       "      <td>Intel gfx driver situation much better with re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8299 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                            content\n",
       "23531          0  &quot;My problem isn't that I miss you... 'cau...\n",
       "8051           0  That's it? It's done already? This is one proo...\n",
       "11499          0  I am so hungry! And there is no food for me to...\n",
       "31288          1  Feet hurt...finally in bed...will not forget t...\n",
       "18561          0                                     really ill atm\n",
       "...          ...                                                ...\n",
       "21697          1  @chocolatesuze yes yes you should! Especially ...\n",
       "19445          0  @kickzfadayz Our boy better get it in tonight!...\n",
       "20216          1             tafe was actually quite good. for once\n",
       "3258           0  10 minutes to boarding; 14 hours to home. no w...\n",
       "27810          0  Intel gfx driver situation much better with re...\n",
       "\n",
       "[8299 rows x 2 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[['sentiment' , 'content']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply bow \n",
    "if train_data.shape[1] > 2 :\n",
    "    train_data = train_data[['sentiment' , 'content']]\n",
    "    test_data = train_data[['sentiment' , 'content']]\n",
    "\n",
    "\n",
    "X_train = train_data['content'].values\n",
    "y_train = train_data['sentiment'].values\n",
    "X_test = test_data['content'].values\n",
    "y_test = test_data['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23531</th>\n",
       "      <td>0</td>\n",
       "      <td>&amp;quot;My problem isn't that I miss you... 'cau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8051</th>\n",
       "      <td>0</td>\n",
       "      <td>That's it? It's done already? This is one proo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11499</th>\n",
       "      <td>0</td>\n",
       "      <td>I am so hungry! And there is no food for me to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31288</th>\n",
       "      <td>1</td>\n",
       "      <td>Feet hurt...finally in bed...will not forget t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18561</th>\n",
       "      <td>0</td>\n",
       "      <td>really ill atm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21697</th>\n",
       "      <td>1</td>\n",
       "      <td>@chocolatesuze yes yes you should! Especially ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19445</th>\n",
       "      <td>0</td>\n",
       "      <td>@kickzfadayz Our boy better get it in tonight!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20216</th>\n",
       "      <td>1</td>\n",
       "      <td>tafe was actually quite good. for once</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>0</td>\n",
       "      <td>10 minutes to boarding; 14 hours to home. no w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27810</th>\n",
       "      <td>0</td>\n",
       "      <td>Intel gfx driver situation much better with re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8299 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                            content\n",
       "23531          0  &quot;My problem isn't that I miss you... 'cau...\n",
       "8051           0  That's it? It's done already? This is one proo...\n",
       "11499          0  I am so hungry! And there is no food for me to...\n",
       "31288          1  Feet hurt...finally in bed...will not forget t...\n",
       "18561          0                                     really ill atm\n",
       "...          ...                                                ...\n",
       "21697          1  @chocolatesuze yes yes you should! Especially ...\n",
       "19445          0  @kickzfadayz Our boy better get it in tonight!...\n",
       "20216          1             tafe was actually quite good. for once\n",
       "3258           0  10 minutes to boarding; 14 hours to home. no w...\n",
       "27810          0  Intel gfx driver situation much better with re...\n",
       "\n",
       "[8299 rows x 2 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Bag of Words (CountVectorizer)\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit the vectorizer on the training data and transform it\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using the same vectorizer\n",
    "X_test_bow = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the vetorizer on the trainning data and transofrm it \n",
    "vectorizer = CountVectorizer(max_features= 500)\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "\n",
    "#transorm the test data using the  same vector\n",
    "X_test_bow = vectorizer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(X_train_bow.toarray())\n",
    "train_df['label'] = y_train\n",
    "test_df = pd.DataFrame(X_test_bow.toarray())\n",
    "test_df['label'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store \n",
    "path = os.path.join('data' , 'features')\n",
    "os.makedirs(path,exist_ok= True)\n",
    "\n",
    "train_df.to_csv(os.path.join(path  , 'train_bow.csv'))\n",
    "test_df.to_csv(os.path.join(path , 'test_bow.csv'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write file now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/feature_engineering.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/feature_engineering.py\n",
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#featch the data from data/preocessed\n",
    "train_data = pd.read_csv(os.path.join('data' , 'processed' , 'train_processed.csv'))\n",
    "test_data = pd.read_csv(os.path.join('data' ,'processed' , 'test_processed.csv'))\n",
    "\n",
    "#remove missing values\n",
    "train_data.fillna('', inplace = True)\n",
    "test_data.fillna('',inplace = True)\n",
    "\n",
    "\n",
    "if train_data.shape[1] > 2 :\n",
    "    train_data = train_data[['sentiment' , 'content']]\n",
    "    test_data = train_data[['sentiment' , 'content']]\n",
    "\n",
    "\n",
    "X_train = train_data['content'].values\n",
    "y_train = train_data['sentiment'].values\n",
    "X_test = test_data['content'].values\n",
    "y_test = test_data['sentiment'].values\n",
    "\n",
    "# Apply Bag of Words (CountVectorizer)\n",
    "vectorizer = CountVectorizer(max_features= 500)\n",
    "\n",
    "# Fit the vectorizer on the training data and transform it\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using the same vectorizer\n",
    "X_test_bow = vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "train_df = pd.DataFrame(X_train_bow.toarray()) \n",
    "train_df['label'] = y_train\n",
    "test_df = pd.DataFrame(X_train_bow.toarray())\n",
    "test_df['label']=y_test\n",
    "\n",
    "#store \n",
    "path = os.path.join('data' , 'features')\n",
    "os.makedirs(path,exist_ok= True)\n",
    "\n",
    "\n",
    "\n",
    "train_df.to_csv(os.path.join(path  , 'train_bow.csv'))\n",
    "test_df.to_csv(os.path.join(path , 'test_bow.csv'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dvc stage add -n feature_engeenering -d src/feature_engineering -d data/processed \n",
    "\n",
    "-o data/features python src/feature_engineering.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run src/feature_engineering.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8299, 501), (8299,))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fetch \n",
    "train_data = pd.read_csv(os.path.join('data','features' , 'train_bow.csv'))\n",
    "X_train = train_data.iloc[: , 0:-1].values \n",
    "y_train = train_data.iloc[:,-1].values\n",
    "X_train.shape , y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8299, 501)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8299,)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "clf = GradientBoostingClassifier(n_estimators= 50)\n",
    "clf = clf.fit(X_train , y_train)\n",
    "\n",
    "#save\n",
    "pickle.dump(clf , open('model.pkl' , 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## writting model file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/model_building.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/model_building.py\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "import os\n",
    "import pickle\n",
    "\n",
    "#fetch \n",
    "train_data =  pd.read_csv(os.path.join('data' , 'features' , 'train_bow.csv'))\n",
    "x_train = train_data.iloc[: , 0:-1]\n",
    "y_train = train_data.iloc[: , -1]\n",
    "\n",
    "#define model and train\n",
    "clf = GradientBoostingClassifier(n_estimators= 50)\n",
    "clf.fit(x_train , y_train)\n",
    "\n",
    "#save \n",
    "pickle.dump(clf,open('model.pkl' , 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run src/model_building.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/model_evaluation.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/model_evaluation.py \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import pickle \n",
    "import json \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import precision_score  , recall_score , roc_auc_score \n",
    "\n",
    "\n",
    "#fetch\n",
    "clf = pickle.load(open('model.pkl','rb'))\n",
    "test_data = pd.read_csv('data/features/test_bow.csv')\n",
    "x_test = test_data.iloc[: , 0:-1].values\n",
    "y_test = test_data.iloc[: , -1].values\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "y_pred_proba = clf.predict_proba(x_test)[: , 1]\n",
    "\n",
    "\n",
    "#calcuate evaluation metrics \n",
    "accuracy = accuracy_score(y_test , y_pred)\n",
    "precision  = precision_score(y_test, y_pred) \n",
    "recall = recall_score(y_test , y_pred)\n",
    "auc = roc_auc_score(y_test , y_pred_proba)\n",
    "\n",
    "metrics_dict = {\n",
    "    'accuracy' : accuracy , \n",
    "    'precision' : precision , \n",
    "    'recall' : recall , \n",
    "    'auc' : auc}\n",
    "\n",
    "with open('metrics.json' , 'w') as file :\n",
    "    json.dump(metrics_dict ,file , indent = 4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\software\\miniconda\\envs\\mlenv\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\software\\miniconda\\envs\\mlenv\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%run src/model_evaluation.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we are saving metrics , as output so that  , given metrics can show and plot in coomand line so \n",
    "##  --metrics metrics.json ....\n",
    " dvc stage add -n model_evaluation -d src/model_evaluation.py -d data/features -d model.pkl --metrics metrics.json python src/model_evaluation.py \n",
    "\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dvc metrics show "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
